{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww5SH0p1vqe8"
      },
      "outputs": [],
      "source": [
        "# Exp 1\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "img=cv2.imread(\"/content/thumbnail.jpeg\")\n",
        "\n",
        "plt.imshow(img);\n",
        "\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img);\n",
        "\n",
        "grey_img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "plt.imshow(grey_img,cmap='gray');\n",
        "\n",
        "img2=cv2.imread(\"/content/thumbnail.jpeg\")\n",
        "plt.imshow(img2);\n",
        "\n",
        "img2=cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img2);\n",
        "\n",
        "grey_img2=cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY)\n",
        "plt.imshow(grey_img2,cmap='gray');\n",
        "\n",
        "img3=cv2.imread(\"/content/thumbnail.jpeg\")\n",
        "plt.imshow(img3);\n",
        "\n",
        "img3=cv2.cvtColor(img3,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img3);\n",
        "\n",
        "grey_img3=cv2.cvtColor(img3,cv2.COLOR_RGB2GRAY)\n",
        "plt.imshow(grey_img3,cmap='gray');\n",
        "\n",
        "hist1=cv2.calcHist([grey_img],[0],None,[255],[0,255])\n",
        "img_2=cv2.equalizeHist(grey_img)\n",
        "hist2=cv2.calcHist([img_2],[0],None,[255],[0,255])\n",
        "plt.subplot(221),plt.imshow(grey_img,cmap='gray');\n",
        "plt.subplot(222),plt.plot(hist1);\n",
        "plt.subplot(223),plt.imshow(img_2,cmap='gray');\n",
        "plt.subplot(224),plt.plot(hist2);\n",
        "\n",
        "hist5=cv2.calcHist([grey_img2],[0],None,[255],[0,255])\n",
        "img_3=cv2.equalizeHist(grey_img2)\n",
        "hist6=cv2.calcHist([img_3],[0],None,[255],[0,255])\n",
        "plt.subplot(221),plt.imshow(grey_img2,cmap='gray');\n",
        "plt.subplot(222),plt.plot(hist1);\n",
        "plt.subplot(223),plt.imshow(img_3,cmap='gray');\n",
        "plt.subplot(224),plt.plot(hist6);\n",
        "\n",
        "th,th_img= cv2.threshold(grey_img2,100,200,cv2.THRESH_BINARY)\n",
        "th,th_img= cv2.threshold(grey_img2,100,250,cv2.THRESH_BINARY_INV)\n",
        "\n",
        "plt.imshow(th_img,cmap='gray');\n",
        "\n",
        "th,th_img1= cv2.threshold(grey_img2,50,100,cv2.THRESH_BINARY)\n",
        "plt.imshow(th_img1,cmap='gray');\n",
        "\n",
        "\n",
        "img4=cv2.imread('/content/mindmon-2.png')\n",
        "img4=cv2.resize(img4,(500,500),interpolation=cv2.INTER_AREA)\n",
        "gray=cv2.cvtColor(img4,cv2.COLOR_BGR2GRAY)\n",
        "blr=cv2.GaussianBlur(gray,(5,5),0)\n",
        "plt.imshow(blr,cmap='gray')\n",
        "edg=cv2.Canny(blr,90,120)\n",
        "\n",
        "plt.imshow(edg,cmap='gray')\n",
        "\n",
        "#ero=cv2.erode(edg,(3,3),iterations=1)\n",
        "dila=cv2.dilate(edg,(7,7),iterations=10)\n",
        "plt.imshow(dila,cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "ero=cv2.erode(edg,(3,3),iterations=1)\n",
        "#dila=cv2.dilate(edg,(7,7),iterations=10)\n",
        "plt.imshow(ero,cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.imshow(np.flipud(gray),cmap='gray')\n",
        "\n",
        "plt.imshow(np.fliplr(gray),cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 2A\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from keras.datasets import cifar10\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10,8)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "plt.imshow(X_train[5])\n",
        "\n",
        "print(\"No. of training images: \", len(X_train))\n",
        "print(\"No. of testing images: \", len(X_test))\n",
        "print(\"Size of each image: \", len(X_train[0]), \"x\", len(X_train[0][0]), \"x\", len(X_train[0][0][0]))\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "k = 4\n",
        "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train, y_train.ravel())\n",
        "y_test_pred = neigh.predict(X_test)\n",
        "num_correct = np.sum(y_test_pred == y_test.ravel())\n",
        "acc = float(num_correct)/len(X_test)\n",
        "print(\"%d/%d correct => accuracy = %f\" % (num_correct,len(X_test), acc))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test_pred, y_test.ravel())\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dxuooO5ewVvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 2B\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,Activation\n",
        "\n",
        "(train_images,train_labels),(test_images,test_labels)= datasets.cifar10.load_data()\n",
        "\n",
        "#Normalizing pixel values to be between 0 and 1\n",
        "train_images,test_images=train_images/255.0,test_images/255.0\n",
        "\n",
        "class_names=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[i])\n",
        "  plt.xlabel(class_names[train_labels[i][0]])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "model=Sequential([\n",
        "    Flatten(input_shape=(32,32,3)),\n",
        "    Dense(250,activation='softmax'),\n",
        "    Dense(128,activation='softmax'),\n",
        "    Dense(18,activation='softmax'),\n",
        "    Dense(10,activation='softmax'),\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "history=model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels))"
      ],
      "metadata": {
        "id": "OTv5WV24yJvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 3\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import normalize,to_categorical\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=cifar10.load_data()\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "train_datagen=ImageDataGenerator(rotation_range=45,width_shift_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "train_generator=train_datagen.flow(X_train,y_train,batch_size=32)\n",
        "\n",
        "activation='relu'\n",
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation=activation,padding='same',input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation=activation,padding='same',kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation=activation,padding='same',kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation=activation,padding='same',kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=activation,kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "history=model.fit_generator(train_generator,steps_per_epoch=250,epochs=10,validation_data=(X_test,y_test))\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(1,len(loss)+1)\n",
        "plt.plot(epochs,loss,'y',label='Training_loss')\n",
        "plt.plot(epochs,val_loss,'r',label='Validation_loss')\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "import visualkeras\n",
        "\n"
      ],
      "metadata": {
        "id": "m_k1EkBVyKV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 6\n",
        "pip install yolov5\n",
        "pip install ultralytics\n",
        "pip install opencv-python\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image_path = '/content/bus.jpg'\n",
        "cv2_imshow(cv2.imread(image_path))\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "results = model(image_path)\n",
        "\n",
        "frame = cv2.imread(image_path)\n",
        "for index, row in results.pandas().xyxy[0].iterrows():\n",
        "    x1 = int(row['xmin'])\n",
        "    y1 = int(row['ymin'])\n",
        "    x2 = int(row['xmax'])\n",
        "    y2 = int(row['ymax'])\n",
        "    d = row['name']\n",
        "    print(d)\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
        "    cv2.putText(frame, d, (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
        "cv2_imshow(frame)\n"
      ],
      "metadata": {
        "id": "MA-JLWOT0LjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 7\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import reuters\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Activation\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "num_words = 30000\n",
        "maxlen = 50\n",
        "test_split = 0.3\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\n",
        "\n",
        "word_index=reuters.get_word_index()\n",
        "word_index['money']\n",
        "\n",
        "index_to_word={}\n",
        "for key,value in word_index.items():\n",
        "  index_to_word[value]=key\n",
        "\n",
        "index_to_word[4]\n",
        "\n",
        "\n",
        "X_train = pad_sequences(X_train, padding = 'post')\n",
        "X_test = pad_sequences(X_test, padding = 'post')\n",
        "\n",
        "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "y_data = np.concatenate((y_train, y_test))\n",
        "y_data = to_categorical(y_data)\n",
        "y_train = y_data[:1395]\n",
        "y_test = y_data[1395:]\n",
        "\n",
        "def lstm():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, input_shape = (49,1), return_sequences = False))\n",
        "    model.add(Dense(46))\n",
        "    model.add(Activation('softmax'))\n",
        "    adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model = KerasClassifier(build_fn = lstm, epochs = 200, batch_size = 50, verbose = 1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_test_ = np.argmax(y_test, axis = 1)\n",
        "print(\"accuracy: \",accuracy_score(y_pred, y_test_))"
      ],
      "metadata": {
        "id": "BuyArCF4xPBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 8\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import reuters\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Activation\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "num_words = 30000\n",
        "maxlen = 50\n",
        "test_split = 0.3\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\n",
        "\n",
        "word_index=reuters.get_word_index()\n",
        "word_index['money']\n",
        "\n",
        "index_to_word={}\n",
        "for key,value in word_index.items():\n",
        "  index_to_word[value]=key\n",
        "\n",
        "index_to_word[4]\n",
        "\n",
        "\n",
        "X_train = pad_sequences(X_train, padding = 'post')\n",
        "X_test = pad_sequences(X_test, padding = 'post')\n",
        "\n",
        "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "y_data = np.concatenate((y_train, y_test))\n",
        "y_data = to_categorical(y_data)\n",
        "y_train = y_data[:1395]\n",
        "y_test = y_data[1395:]\n",
        "\n",
        "def vanilla_rnn():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(50, input_shape = (49,1), return_sequences = False))\n",
        "    model.add(Dense(46))\n",
        "    model.add(Activation('softmax'))\n",
        "    adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model = KerasClassifier(build_fn = vanilla_rnn, epochs = 200, batch_size = 50, verbose = 1)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_ = np.argmax(y_test, axis = 1)\n",
        "print(accuracy_score(y_pred, y_test_))    "
      ],
      "metadata": {
        "id": "nC7ukhDB1KqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 9\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "model = torchvision.models.vgg19(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "img = Image.open('/content/bus.jpg') \n",
        "\n",
        "image = mpimg.imread('/content/bus.jpg')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "def preprocess(image, size=224):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((size,size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0,0,0], std=[1,1,1]),\n",
        "        T.Lambda(lambda x: x[None]),\n",
        "    ])\n",
        "    return transform(image)\n",
        "    \n",
        "X = preprocess(img)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "X.requires_grad_()\n",
        "\n",
        "scores = model(X)\n",
        "score_max_index = scores.argmax()\n",
        "score_max = scores[0,score_max_index]\n",
        "print(score_max_index,score_max)\n",
        "score_max.backward()\n",
        "\n",
        "saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
        "print(saliency)\n",
        "plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zpxNtr9O1K6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exp 11\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Define the questions and answers\n",
        "questions = [\"hi\",\"what is your name?\",\"bye\"]\n",
        "answers = [\"Hello\",\"My name is Chatbot.\",\"Good bye\"]\n",
        "\n",
        "# Define a vocabulary and mapping from words to indices\n",
        "l=(\" \".join(questions)).split()\n",
        "vocab={j:i for i,j in enumerate(l)}\n",
        "print(vocab)\n",
        "\n",
        "# Convert the questions and answers to numerical form\n",
        "X = np.zeros((len(questions), len(vocab)), dtype=np.float32)\n",
        "Y = np.zeros((len(answers), len(answers)), dtype=np.float32)\n",
        "for i, question in enumerate(questions):\n",
        "    for word in question.lower().split():\n",
        "        if word in vocab:\n",
        "            X[i, vocab[word]] = 1.0\n",
        "    Y[i, i] = 1.0\n",
        "print(X)\n",
        "print()\n",
        "print(Y)\n",
        "\n",
        "# Define the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(len(vocab),)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(answers), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the questions and answers\n",
        "model.fit(X, Y, epochs=10)\n",
        "\n",
        "# Define a function to generate a response from the model\n",
        "def generate_response(input_text):\n",
        "    x = np.zeros((1, len(vocab)), dtype=np.float32)\n",
        "    for word in input_text.lower().split():\n",
        "        if word in vocab:\n",
        "            x[0, vocab[word]] = 1.0\n",
        "    y = model.predict(x)[0]\n",
        "    index = np.argmax(y)\n",
        "    print(index)\n",
        "    return answers[index]\n",
        "    \n",
        "# Ask for user input and generate a response\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    response = generate_response(user_input)\n",
        "    print(\"Chatbot:\", response)    "
      ],
      "metadata": {
        "id": "HCnzfOpM1LJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GzwubPIK1LSi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}